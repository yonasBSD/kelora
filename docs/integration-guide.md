# **Kelora Integration Guide**

*Composing with the right tools makes logs sing.*

Kelora is the log scalpel â€” it shapes raw text into structured events.
Once logs are clean, other tools can filter, analyze, or visualize them with elegance.
This guide shows how Kelora pairs with a handful of timeless allies that share its spirit:
small, sharp, and scriptable.

---

## ğŸ§© Core Idea

**Kelora normalizes. Others analyze.**
Use it to turn noise into structure â€” JSONL, TSV, or logfmt â€” then pipe the result onward.
Every tool below does one thing brilliantly.

---

## âš™ï¸ The Essential Five

### **[jq](https://jqlang.github.io/jq/) / [jaq](https://github.com/01mf02/jaq) â€” Deep JSON slicing**

Kelora emits JSONL; jq dissects it.

```bash
kelora -f combined -F json --filter 'e.status >= 500' \
| jq -r '. | [.ts, .path, .status] | @tsv'
```

* `jq`â€™s power meets Keloraâ€™s discipline â€” no malformed JSON, ever.
* `jaq` is a Rust rewrite thatâ€™s orders faster; perfect for big logs.

ğŸ’¡ *Bonus*: jq can stream-parse gigabytes; Keloraâ€™s `--parallel` keeps up.

---

### **[qsv](https://github.com/jqnatividad/qsv) â€” Lightning CSV analytics**

For top-Ns, counts, or quick histograms:

```bash
kelora -f json -F csv --keys ts,service,status \
| qsv frequency --column service --limit 10
```

* qsv runs Rust-fast and memory-light.
* Combine with `--stats` or `--metrics` for instant dashboards without dashboards.

ğŸ’¡ *Tip*: use `kelora --exec 'e.day = e.ts.format("%F")'` to enrich timestamps for time-based grouping.

---

### **[VisiData](https://www.visidata.org/) â€” Interactive spelunking**

Turn structured output into an instant spreadsheet:

```bash
kelora -f logfmt -F tsv --keys ts,level,msg | vd -
```

* Sort, pivot, graph â€” all inside your terminal.
* Streams stay live: press `g#` for group counts, `/` for filtering, or `Shift+G` for plots.

ğŸ’¡ *Pair with*: `--window` in Kelora to feed contextual streams into VisiData for exploration.

---

### **[spyql](https://github.com/dcmoura/spyql) â€” SQL on streams**

SQL aggregation, no database needed:

```bash
kelora -j -F json --keys ts,user,action \
| spyql -O table "SELECT user, COUNT(*) c FROM input GROUP BY user ORDER BY c DESC"
```

* Feels like SQLite, runs like awk.
* Works perfectly with `kelora --exec` transformations.

ğŸ’¡ *Mix-in*: `emit_each()` fan-outs from arrays, turning nested JSON into rows for SpyQL to count.

---

### **[rare](https://github.com/zix99/rare) â€” Regex histograms**

Quick regex-driven insights:

```bash
kelora -f syslog -k msg | rare -r 'error|warn|timeout'
```

* Shows dominant patterns â€” perfect for first-look diagnostics.
* Add `--since`/`--until` to narrow the temporal window.

ğŸ’¡ *Pro tip*: Pipe structured Kelora fields into `rare -r` for statistical debugging.

---

## ğŸ—ï¸ Unix Classics â€” The Original Power Tools

Kelora speaks fluent POSIX.

### **awk â€” Stream arithmetic**

```bash
kelora -F tsv --keys ts,service,status \
| awk -F'\t' '$3 >= 500 {print $1, $2, $3}'
```

* For quick ratios, deltas, or counters â€” awk still rules.
* Keloraâ€™s clean TSV guarantees no quoting nightmares.

ğŸ’¡ *Enrich first*: `--exec 'e.delta = e.end.to_int() - e.start.to_int()'` then post-process in awk.

---

### **cut / sort / uniq â€” The timeless trio**

```bash
kelora -F tsv --keys service \
| cut -f1 | sort | uniq -c | sort -nr | head
```

* Minimal, composable, transparent.
* Keloraâ€™s field normalization makes these safe and predictable.

ğŸ’¡ *Trick*: `kelora -F tsv --keys ip | sort | uniq -c` gives quick top IPs from any format.

---

### **sqlite3 â€” Instant structured DB**

```bash
kelora -F tsv --keys ts,service,status > events.tsv
sqlite3 :memory: <<'SQL'
.mode tabs
.import events.tsv events
SELECT service, COUNT(*) FROM events GROUP BY service ORDER BY 2 DESC;
SQL
```

* Treat logs as tables; run ad-hoc joins or time filters.
* SQLite loves Keloraâ€™s TSV output â€” no schema headaches.

ğŸ’¡ *Hack*: combine with `kelora --exec 'e.day = e.ts.format("%F")'` for date-based rollups.

---

## ğŸ§­ Interactive Explorers â€” Watch Logs Breathe

### **[lnav](https://lnav.org/) â€” The Living Log Viewer**

```bash
kelora -f json -F json app.log | lnav -i json
```

* lnav auto-detects timestamps, builds timelines, and runs SQL.
* Kelora feeds it pristine structure â€” lnav handles the live browsing.

ğŸ’¡ Run inside lnav:

```
;SELECT level, COUNT(*) FROM log GROUP BY level;
```

---

### **[klogg](https://klogg.filimonov.dev/) â€” GUI grep for giants**

```bash
kelora -f syslog --filter 'e.level == "error"' > errors.log
klogg errors.log
```

* Opens terabyte logs instantly.
* Use it when `less` starts to sweat.

ğŸ’¡ Combine with `--pretty-ts` for readable time context in visual searches.

---

### **[tailspin](https://github.com/bensadeh/tailspin) â€” Streaming color**

```bash
kelora -f combined | tailspin
```

* Colorized, leveled tails for real-time debugging.
* Matches Keloraâ€™s `--realtime` mode perfectly.

---

### **[Benthos](https://www.benthos.dev/) â€” Stream orchestration**

```bash
benthos -c benthos.yaml | kelora -f json --exec 'e.env = "prod"' -F json
```

* Benthos handles I/O, Kelora handles semantics.
* Together they form a declarative, testable log refinery.

---

## ğŸ”„ Model Workflows

### From chaos to clarity

```bash
tail -f /var/log/nginx/access.log \
| kelora -f combined --filter 'e.status >= 500' \
  --keys ts,path,status -F csv \
| qsv frequency -c path --limit 20
```

Or interactively:

```bash
kelora -f json -F tsv --keys ts,level,msg app.log | vd -
```

Or classically:

```bash
kelora -f logfmt -F tsv --keys level | cut -f1 | sort | uniq -c
```

**Kelora parses and filters â€” everything else explores and aggregates.**

---

## ğŸŒ Inbound & Outbound

**Inbound:** raw logs, JSONL, syslog, logfmt, csv/tsv, gzipped streams.
â†’ Preprocessors like [`jc`](https://github.com/kellyjonbrazil/jc) (for shell command output) or [`evtx2json`](https://github.com/omerbenamram/evtx) (for Windows event logs) slot right in.

**Outbound:** `-F json`, `-F csv`, or `-F tsv` depending on what follows.
Use `--keys`, `--filter`, and `--exec` to shape before export.

---

## ğŸ§˜ Philosophy Recap

Kelora doesnâ€™t compete â€” it completes.
Itâ€™s the prelude to every great analysis: clean in, clean out.
Logs, refined to truth.
Then â€” pass them on.

---

Would you like me to add a short â€œ**Integration Recipes Appendix**â€ next â€” e.g. *â€œTop IPs in 10 waysâ€* showing the same goal solved with `awk`, `qsv`, `jq`, `sqlite3`, etc.? That would turn this into a practical companion for advanced users.
